[{"data":1,"prerenderedAt":156},["ShallowReactive",2],{"content-query-Jy7Ld6swn0":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":7,"title":8,"description":9,"date":10,"body":11,"_type":150,"_id":151,"_source":152,"_file":153,"_stem":154,"_extension":155},"/blog/robots","blog",false,"","C贸mo implementar un archivo robots.txt en un proyecto Nuxt Js","Tener un archivo robots.txt es muy importante ya que ayuda a controlar que Google y otros motores de b煤squeda como Bing indexen el contenido del sitio web. Esto se debe a que lo primero que revisa un rastreador cuando visita un sitio web es si existe robots.txt, por lo que determina cu谩ndo se debe rastrear el contenido o no.","2023-03-12",{"type":12,"children":13,"toc":142},"root",[14,21,26,33,38,48,53,61,67,72,80,86,91,99,105,110,118,124,129,137],{"type":15,"tag":16,"props":17,"children":18},"element","p",{},[19],{"type":20,"value":9},"text",{"type":15,"tag":16,"props":22,"children":23},{},[24],{"type":20,"value":25},"Hay varias formas de agregar robots.txt y es tan f谩cil como escribirlo manualmente en la carpeta \"statics\". Pero para este tutorial, usaremos nuxtjs/robots ya que es m谩s flexible y el contenido de robots.txt se puede manipular f谩cilmente.",{"type":15,"tag":27,"props":28,"children":30},"h2",{"id":29},"instalar-el-paquete-nuxtjsrobots",[31],{"type":20,"value":32},"Instalar el paquete nuxtjs/robots",{"type":15,"tag":16,"props":34,"children":35},{},[36],{"type":20,"value":37},"Lo primero es lo primero, instala el paquete de robots y def铆nelo en la matriz de m贸dulos de nuxt.config.js.",{"type":15,"tag":39,"props":40,"children":42},"pre",{"code":41},"yarn add @nuxtjs/robots\n",[43],{"type":15,"tag":44,"props":45,"children":46},"code",{"__ignoreMap":7},[47],{"type":20,"value":41},{"type":15,"tag":16,"props":49,"children":50},{},[51],{"type":20,"value":52},"Para definir la configuraci贸n de robots, podemos pasar un objeto, una matriz o una funci贸n, donde cada m茅todo tiene sus propios casos de uso.",{"type":15,"tag":39,"props":54,"children":56},{"code":55},"export default {\n  modules: [\n    '@nuxtjs/robots'\n  ],\n  robots: {\n    /* opciones del m贸dulo */\n  }\n}\n",[57],{"type":15,"tag":44,"props":58,"children":59},{"__ignoreMap":7},[60],{"type":20,"value":55},{"type":15,"tag":27,"props":62,"children":64},{"id":63},"configuraci贸n-simple",[65],{"type":20,"value":66},"Configuraci贸n simple",{"type":15,"tag":16,"props":68,"children":69},{},[70],{"type":20,"value":71},"En este caso, define el c贸digo de la siguiente manera y permitir谩 que todos los agentes de usuario (bot) rastreen el sitio. En cambio, si el valor de Disallow es \"/\", entonces no permitimos que se rastree ninguna de las p谩ginas.",{"type":15,"tag":39,"props":73,"children":75},{"code":74},"export default {\n  robots: {\n    UserAgent: '*',\n    Disallow: ''\n  }\n}\n",[76],{"type":15,"tag":44,"props":77,"children":78},{"__ignoreMap":7},[79],{"type":20,"value":74},{"type":15,"tag":27,"props":81,"children":83},{"id":82},"configuraci贸n-de-m煤ltiples-agentes-de-usuario",[84],{"type":20,"value":85},"Configuraci贸n de m煤ltiples agentes de usuario",{"type":15,"tag":16,"props":87,"children":88},{},[89],{"type":20,"value":90},"Si desea especificar una configuraci贸n para un agente de usuario diferente, pase la matriz de objetos como valor de robots y se comportar谩 como se define.",{"type":15,"tag":39,"props":92,"children":94},{"code":93},"export default {\n  robots: [\n    {\n      UserAgent: 'Googlebot',\n      Disallow: '/usuario',\n    },\n    {\n      UserAgent: '*',\n      Disallow: '/admin',\n    },\n  ]\n}\n",[95],{"type":15,"tag":44,"props":96,"children":97},{"__ignoreMap":7},[98],{"type":20,"value":93},{"type":15,"tag":27,"props":100,"children":102},{"id":101},"configuraci贸n-de-funci贸n",[103],{"type":20,"value":104},"Configuraci贸n de funci贸n",{"type":15,"tag":16,"props":106,"children":107},{},[108],{"type":20,"value":109},"Tambi茅n puede pasar una funci贸n como valor de robots y, en este caso, definir la l贸gica o definir condicionalmente el valor del robot que desea que sea.",{"type":15,"tag":39,"props":111,"children":113},{"code":112},"export default {\n  robots: () => {\n    if (algunaLogicaAqu铆) {\n      return {\n        UserAgent: '*',\n        Disallow: '/'\n      }\n    }\n  }\n}\n",[114],{"type":15,"tag":44,"props":115,"children":116},{"__ignoreMap":7},[117],{"type":20,"value":112},{"type":15,"tag":27,"props":119,"children":121},{"id":120},"ejecutar-yarn-dev-npm-run-dev",[122],{"type":20,"value":123},"Ejecutar \"yarn dev\" / \"npm run dev\"",{"type":15,"tag":16,"props":125,"children":126},{},[127],{"type":20,"value":128},"Finalmente, ejecuta \"yarn dev\" y ahora puedes visitar /robots.txt para ver el valor de robots.txt que has definido.",{"type":15,"tag":39,"props":130,"children":132},{"code":131},"User-agent: Googlebot\nDisallow: /usuarios\nUser-agent: Bingbot\nDisallow: /admin\n",[133],{"type":15,"tag":44,"props":134,"children":135},{"__ignoreMap":7},[136],{"type":20,"value":131},{"type":15,"tag":16,"props":138,"children":139},{},[140],{"type":20,"value":141},"Este post fue originalmente publicado en PostSrc ヰヰ. Si te gustan este tipo de tutoriales, realmente apreciar铆a si le das una visita.",{"title":7,"searchDepth":143,"depth":143,"links":144},2,[145,146,147,148,149],{"id":29,"depth":143,"text":32},{"id":63,"depth":143,"text":66},{"id":82,"depth":143,"text":85},{"id":101,"depth":143,"text":104},{"id":120,"depth":143,"text":123},"markdown","content:blog:robots.md","content","blog/robots.md","blog/robots","md",1769621611563]