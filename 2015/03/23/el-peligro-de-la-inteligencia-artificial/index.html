<!DOCTYPE html>
<html lang="es">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>El peligro de la inteligencia artificial | De die in diem</title>
<link rel="stylesheet" href="https://jorgeikeda.com/css/style.css">
<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/styles/github.min.css">


<section class="section">
  <div class="container">
    <nav class="nav">
      <div class="nav-left">
        <a class="nav-item" href="https://jorgeikeda.com"><h1 class="title is-4">De die in diem</h1></a>
      </div>
      <div class="nav-right">
        <nav class="nav-item level is-mobile">
          
          <a class="level-item" href="https://github.com/freebot">
            <span class="icon">
              <i class="fa fa-github"></i>
            </span>
          </a>
          
          <a class="level-item" href="https://twitter.com/jorgeikeda">
            <span class="icon">
              <i class="fa fa-twitter"></i>
            </span>
          </a>
          
          <a class="level-item" href="/index.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>
          </a>
          
        </nav>
      </div>
    </nav>
  </div>
</section>

<section class="section">
  <div class="container">
    <h2 class="subtitle is-6">March 23, 2015</h2>
    <h1 class="title">El peligro de la inteligencia artificial</h1>
    <div class="content">
      <p>En la <a href="http://www.jorgeikeda.com/wordpress/?p=6698">entrada anterior</a> al blog comentaba que Kant, citado por Isaiah Berlin, decía que la esencia de la libertad del sujeto consiste en que él y sólo él se dé las órdenes a obedecer. En el mismo sentido se pronuncia Mijaíl Bakunin en la obra <em>El principio de Autoridad</em>:</p>

<blockquote>Cuando se trata de zapatos, prefiero la autoridad del zapatero; si se trata de una casa, de un canal o de un ferrocarril, consulto la del arquitecto o del ingeniero. Para esta o la otra, ciencia especial me dirijo a tal o cual sabio. Pero no dejo que se impongan a mí ni el zapatero, ni el arquitecto ni el sabio.
Les escucho libremente y con todo el respeto que merecen su inteligencia, su carácter, su saber, pero me reservo mi derecho incontestable de crítica y de control.</blockquote>

<p>Bakunin no se limita a la opinión de un especialista, sino que consulta a varios antes de tomar una decisión. No reconoce autoridad infalible, por lo que no tiene fe en nadie.</p>

<blockquote>Una fe semejante sería fatal a mi razón, la libertad y al éxito mismo de mis empresas; me transformaría inmediatamente en un esclavo estúpido y en un instrumento de la voluntad y de los intereses ajenos.</blockquote>

<p>Bakunin se inclina por la opinión de los especialistas porque le es impuesta por su propia razón, pero como se mencionó anteriormente, escucha a los especialistas y se inclina por la opinión que le parece más justa. De hecho, no habría un hombre que fuera especialista en todo.</p>

<blockquote>La más grande inteligencia no podría abarcar el todo. De donde resulta para la ciencia tanto como para la industria, la necesidad de la división y de la asociación del trabajo. Yo recibo y doy, tal es la vida humana.
Cada uno es autoridad dirigente y cada uno es dirigido a su vez. Por tanto no hay autoridad fija y constante, sino un cambio continuo de autoridad y de subordinación mutuas, pasajeras y sobre todo voluntarias.</blockquote>

<p>Y surge la pregunta sobre qué pasaría si apareciera una inteligencia que fuera especialista en todo. Hasta el momento, las computadoras pueden leer exotéricamente, es decir, pueden pronunciar los sonidos sin entender el mensaje. Pero en una conferencia titulada “<a href="http://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn">The wonderful and terrifying implications of computers can learn</a>” publicada en el sitio TED.com, el conferencista; Jeremy Howard, explica las maravillas de la inteligencia artificial y del uso que le da a esta tecnología para analizar tomografías. La máquina analiza las imágenes y es capaz de distinguir entre las que tienen cáncer y las que no. Desafortunadamente la máquina ha aprendido a leer esotéricamente y a comprender las imágenes.
Como se comentó en <a href="http://www.jorgeikeda.com/wordpress/?p=5431">esta entrada</a> al blog, Sartre, citado por Sartori, decía que conocemos perceptivamente, por concepto o por imágenes, lo que Sartori reducía a imágenes percibidas, imágenes concebidas e imágenes fantásticas. El primer tipo de imagen producirá un saber descriptivo. Una vez que la computadora ha aprendido a distinguir el frente de un automóvil, puede mostrar fotografías de distintos frentes y separarlas de las que muestran la parte trasera del auto. La computadora ha logrado describir imágenes y decir de una imagen que hay un señor pescando, por ejemplo.
Las imágenes concebidas producen un tipo de conocimiento “ideativo” y las imágenes alusivas producen un tipo de conocimiento distinto a los otros dos. ¿Qué sucederá cuando la computadora comprenda el significado de los conceptos Estado, democracia, dictadura, etcétera? ¿O cuando la computadora entienda lo que es un unicornio? Esta computadora podrá leer y entender todos los libros publicados y escaneados hasta la fecha. La computadora podría decidir que los seres humanos no merecen vivir y hacer de todo para exterminarlos.
<a href="http://www.jorgeikeda.com/wordpress">Stephen Hawking</a> ha dicho que la inteligencia artificial podría significar el fin de la raza humana. Los robots podrían tomar el control y desplazar a los seres humanos. Perfeccionarse a ellos mismos hasta superar a los humanos.
<a href="http://www.jorgeikeda.com/wordpress">Elton Musk</a>, fundador de empresas como Paypal y Tesla, ha dicho que la inteligencia artificial puede ser más peligrosa que las armas nucleares.
Lo mismo hubiera dicho Bakunin, que en la citada obra argumenta:</p>

<blockquote>Esa misma razón me impide, pues, reconocer una autoridad fija, constante y universal, porque no hay hombre universal, hombre que sea capaz de abarcar con esa riqueza de detalles (sin la cual la aplicación de la ciencia a la vida no es posible), todas las ciencias, todas las ramas de la vida social. Y si una tal universalidad pudiera realizarse en un solo hombre, quisiera prevalerse de ella para imponemos su autoridad, habría que expulsar a ese hombre de la sociedad, porque su autoridad reduciría inevitablemente a todos los demás a la esclavitud y a la imbecilidad.</blockquote>

    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <aside><div id="disqus_thread"></div></aside>
    <script type="text/javascript">
      var disqus_shortname = 'shortname';
      (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
  </div>
</section>


<section class="section">
  <div class="container has-text-centered">
    <p>&copy; <a href="https://github.com/freebot">Jorge Ikeda</a> 2017</p>
  </div>
</section>
<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/highlight.min.js"></script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/languages/go.min.js"></script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/languages/dockerfile.min.js"></script>

<script>hljs.initHighlightingOnLoad();</script>


